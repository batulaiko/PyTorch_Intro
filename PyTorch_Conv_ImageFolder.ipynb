{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea71e1c7-ae41-4fa4-99b8-b89c4e2dfc77",
   "metadata": {},
   "source": [
    "# Image Classification with Custom ImageFolder Dataset in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "266c19bd-e085-4f0a-b2e6-b2b0be84e9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22d7d7-acdf-42d1-90fe-14f7c8cbe705",
   "metadata": {},
   "source": [
    "# ImageFolder Dataset \n",
    "* convert images to tensors\n",
    "* Images have 3 channels (Red, Green, Blue, RGB)\n",
    "* normalize RGB pixel values for each channel with a mean of (0.485, 0.456, 0.406)\n",
    "* normalize RGB pixel values for each channel with a std of (0.229, 0.224, 0.225)\n",
    "* These mean and std values are computed from Imagenet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dd85ec1-699e-4f0a-829a-fd7652d02411",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize((28, 28)), # Resize image into these dimensions\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f5381e-7e74-412d-9e06-a5b86b994ea1",
   "metadata": {},
   "source": [
    "### Weather Image Recognition Dataset\n",
    "* Download: https://www.kaggle.com/datasets/jehanbhathena/weather-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "813ddbc3-bbe5-4a8a-87ff-b9e399598d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_folder = './data/Weather Image Recognition/'\n",
    "\n",
    "full_dataset = datasets.ImageFolder(\n",
    "    root=data_root_folder, \n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab9569-5384-47cd-ab7c-8d217a1a1601",
   "metadata": {},
   "source": [
    "### See all classes\n",
    "* integer mapping of string names\n",
    "* (Remember models don't work with strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86854115-7e21-4256-a51f-2749b3238e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dew',\n",
       " 'fogsmog',\n",
       " 'frost',\n",
       " 'glaze',\n",
       " 'hail',\n",
       " 'lightning',\n",
       " 'rain',\n",
       " 'rainbow',\n",
       " 'rime',\n",
       " 'sandstorm',\n",
       " 'snow']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6c63c92-19fa-454f-81b4-ff40153e4035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(full_dataset.classes)\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134e8248-7bf6-4db5-bb87-faad36974898",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71c9e7db-d27c-4c16-a13f-b920c25c40c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train len: 5489\n",
      "Test len: 1373\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.80\n",
    "\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(split_ratio * total_size)  # 80% for training\n",
    "test_size = total_size - train_size  # 20% for testing\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "print(f'Train len: {len(train_dataset)}')\n",
    "print(f'Test len: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dfea0bf-5dc6-4d81-95a4-69347931cb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "ex_img, ex_target = train_dataset[0] # img, seg_mask\n",
    "\n",
    "print(ex_img.shape)\n",
    "print(ex_target) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d2b5b0-1090-4ad1-bda0-138fc6285cc1",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ac8df78-722b-4b54-9b68-6b92dc72ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09276768-cbf4-4506-ba71-378aa8ea646f",
   "metadata": {},
   "source": [
    "### Get sample batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a633bc5-b7d5-43a2-9ef6-6959b6540f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "ex_img_batch, ex_target_batch = next(iter(train_dataloader))\n",
    "print(ex_img_batch.shape)\n",
    "print(ex_target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1530837-98b8-429a-b2b0-356eb1edd436",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d32c0fc-5d30-4ae3-8952-2139d044a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        \n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #######################\n",
    "        # Convolutional Part\n",
    "        #######################\n",
    "        #print(f'Input dims: {x.shape}')\n",
    "        \n",
    "        x = self.conv1(x) # (N, 1, 28, 28) -> (N, 32, 26, 26)\n",
    "        #print(f'After conv1 {x.shape}')\n",
    "        x = self.relu(x) # no dim change\n",
    "        x = self.conv2(x) # (N, 32, 26, 26) -> (N, 64, 24, 24)\n",
    "        #print(f'After conv2 {x.shape}')\n",
    "        x = self.relu(x) # no dim change\n",
    "        x = self.max_pool(x) # (N, 64, 24, 24) -> (N, 64, 12, 12)\n",
    "        #print(f'After maxpool {x.shape}')\n",
    "        #######################\n",
    "        #######################\n",
    "\n",
    "        #######################\n",
    "        ## Fully Connected Part\n",
    "        #######################\n",
    "        x = torch.flatten(x, 1) # (N, 64, 12, 12) -> (N, 64*12*12) -> (N, 9216)\n",
    "        x = self.fc1(x) # (N, 9216) -> (N, 128)\n",
    "        x = self.relu(x) # no dim change\n",
    "        logits = self.fc2(x) # (N, 128) - (N, 10)\n",
    "        #######################\n",
    "        #######################\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e8bff8-0909-4a56-a0ef-a93383dc5f85",
   "metadata": {},
   "source": [
    "### Dummy Input for Dimentional Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa53ac93-5ff9-407a-b317-0b29bf9b03b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(\n",
    "    input_channels=3, # 3 for RGB images \n",
    "    num_classes=NUM_CLASSES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afa199a8-3bad-44d1-b20f-1394d4c13e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 3, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73fdfd1a-5b83-4a89-a385-ae50cf3d2f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_preds = model(dummy_input)\n",
    "dummy_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af089da4-9faf-4345-ab35-cb06f15ed7ea",
   "metadata": {},
   "source": [
    "## Print Model Parametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69eec7c4-8738-4e74-a8dc-873dc15c39df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 32, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a18b9e-6ef5-4d35-9f32-2d68d6eebda4",
   "metadata": {},
   "source": [
    "## Print with Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aa09b96-ab09-437f-9694-e193a1d553b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: conv1.weight and parameter data: torch.Size([32, 3, 3, 3])\n",
      "\n",
      "name: conv1.bias and parameter data: torch.Size([32])\n",
      "\n",
      "name: conv2.weight and parameter data: torch.Size([64, 32, 3, 3])\n",
      "\n",
      "name: conv2.bias and parameter data: torch.Size([64])\n",
      "\n",
      "name: fc1.weight and parameter data: torch.Size([128, 9216])\n",
      "\n",
      "name: fc1.bias and parameter data: torch.Size([128])\n",
      "\n",
      "name: fc2.weight and parameter data: torch.Size([11, 128])\n",
      "\n",
      "name: fc2.bias and parameter data: torch.Size([11])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    print(f'name: {n} and parameter data: {p.shape}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dbcdf7-8fb8-4806-802d-517e93cc5bb8",
   "metadata": {},
   "source": [
    "# Optimizer & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbb57fef-8e78-4933-9bba-d233099fef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "learning_rate = 0.02\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=learning_rate\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # Negative log-likehood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4074574d-6d9f-4e24-b31c-7b632b4a0d23",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c63a8d8f-ae53-4779-8fdf-a73c510cf789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    for batch_idx, (img, target) in enumerate(train_loader):\n",
    "        # Move to GPU (if available)\n",
    "        img = img.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(img)\n",
    "        # Compute gradients\n",
    "        loss = criterion(preds, target)\n",
    "        \n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        # In PyTorch, gradients are accumulated, you need to reset gradients in each loop\n",
    "        optimizer.zero_grad()\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update parameters (weights and biases)\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "    avg_loss = sum(loss_history)/len(loss_history)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d7a8f3-97a9-47c4-ae8f-152cff9f43fa",
   "metadata": {},
   "source": [
    "# Testing\n",
    "* No trainin in testing code\n",
    "* Disable Autograd\n",
    "* No optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9681684-6f03-4315-bc03-137f0f6c4619",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    loss_history = []\n",
    "    acc_history = []\n",
    "    \n",
    "    for img, target in test_loader:\n",
    "        # Move to GPU (if available)\n",
    "        img = img.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(img)\n",
    "        # Compute error\n",
    "        loss = criterion(preds, target)\n",
    "        \n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(preds, 1)\n",
    "        accuracy = (predicted == target).sum().item() / target.size(0)\n",
    "\n",
    "        loss_history.append(loss.item())\n",
    "        acc_history.append(accuracy)\n",
    "    \n",
    "    avg_loss = sum(loss_history)/len(loss_history)\n",
    "    avg_acc = sum(acc_history)/len(acc_history)\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf4709d-ff10-42ff-9bf2-d8452c3ff7fb",
   "metadata": {},
   "source": [
    "### Start Training\r\n",
    "* Training consists of two steps: forward and backward propagation\r\n",
    "* In forward propagation, we input the data into the model and measure the error (with loss function)\r\n",
    "* In backward propagation, we adjust the internal paramters of the model so that model makes better predictions next time\r\n",
    "* One complete cycle of the dataset is called \"epoch\" (one loop cycle of all data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de20bdf1-d69b-491d-a16c-d5fa8d33e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_training(model, train_dataloader, test_dataloader, optimizer, criterion, num_epochs, print_interval):\n",
    "\n",
    "    # Loop over all epochs\n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        avg_train_loss = train(model, train_dataloader, optimizer, criterion, epoch)\n",
    "        avg_test_loss, avg_test_acc = test(model, test_dataloader, criterion)\n",
    "\n",
    "        if (epoch + 1) % print_interval == 0:\n",
    "            print(f'Epoch: [{epoch+1}/{num_epochs}], Avg train loss: {avg_train_loss:.4f}, test loss: {avg_test_loss:.4f}, test_acc: {avg_test_acc*100.0:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286f25a-d517-42df-af0d-530405ab509c",
   "metadata": {},
   "source": [
    "### NOTE: this dataset is larger, training takes longer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eedfd3d1-ebbd-4182-9369-862f9e265935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2/20], Avg train loss: 1.9248, test loss: 1.5932, test_acc: 49.64%\n",
      "Epoch: [4/20], Avg train loss: 1.3963, test loss: 1.3502, test_acc: 56.18%\n",
      "Epoch: [6/20], Avg train loss: 1.1920, test loss: 1.2085, test_acc: 59.61%\n",
      "Epoch: [8/20], Avg train loss: 1.0545, test loss: 1.1053, test_acc: 63.39%\n",
      "Epoch: [10/20], Avg train loss: 0.9547, test loss: 1.0780, test_acc: 64.40%\n",
      "Epoch: [12/20], Avg train loss: 0.8762, test loss: 1.0672, test_acc: 64.55%\n",
      "Epoch: [14/20], Avg train loss: 0.8051, test loss: 1.0637, test_acc: 66.14%\n",
      "Epoch: [16/20], Avg train loss: 0.7340, test loss: 1.0641, test_acc: 66.00%\n",
      "Epoch: [18/20], Avg train loss: 0.6606, test loss: 1.0644, test_acc: 66.93%\n",
      "Epoch: [20/20], Avg train loss: 0.5860, test loss: 1.0682, test_acc: 67.01%\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 20\n",
    "print_interval = 2 \n",
    "\n",
    "start_training(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    NUM_EPOCHS,\n",
    "    print_interval\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df9dd1d-1a41-4566-b221-797a810db108",
   "metadata": {},
   "source": [
    "# Save/Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd05fecf-fb3c-45b9-beba-e738d8712d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'class_str_names': full_dataset.classes,\n",
    "},\n",
    "    'convnet_ImageFolder_checkpoint.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b125f-6a85-44dd-b322-64e01b61fa6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
